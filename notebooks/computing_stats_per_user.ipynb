{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expected-trigger",
   "metadata": {},
   "source": [
    "# Computing stats per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "from mbti_type_from_text.db_utils import create_connection\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "import numpy as np\n",
    "import emot  # https://github.com/NeelShah18/emot\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "asian-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = create_connection(\"../data/reddit.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-measurement",
   "metadata": {},
   "source": [
    "# 1. Grouping messages by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "billion-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_sql(sql=\"SELECT * FROM Comments\", con=db_connection)\n",
    "# output of reddit_exploration 1. (users with mbti_type)\n",
    "users_df = pd.read_feather(\"../data/users_df_with_mbti_type.feather\")\\\n",
    "    .fillna(np.nan)  # apparently, feather treats \"NaN\" as \"None\", converting back to \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electrical-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>mbti_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6i0rnp1p</td>\n",
       "      <td>igid221</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1s8dnq6p</td>\n",
       "      <td>Sheilaahmad</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b708k</td>\n",
       "      <td>lzkbloodmage</td>\n",
       "      <td>INFJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mkfu3</td>\n",
       "      <td>ShannyPantsxo</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vh9kmmx</td>\n",
       "      <td>lala2love</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id           name mbti_type\n",
       "0  6i0rnp1p        igid221      INFJ\n",
       "1  1s8dnq6p    Sheilaahmad       NaN\n",
       "2     b708k   lzkbloodmage      INFJ\n",
       "3     mkfu3  ShannyPantsxo       NaN\n",
       "4   vh9kmmx      lala2love       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "common-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>contents</th>\n",
       "      <th>all_content</th>\n",
       "      <th>n_msgs</th>\n",
       "      <th>msgs</th>\n",
       "      <th>character_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100fu2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...</td>\n",
       "      <td>[ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...</td>\n",
       "      <td>965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100sih</th>\n",
       "      <td>[]</td>\n",
       "      <td>[Path of least resistance so I can go back to ...</td>\n",
       "      <td>[Path of least resistance so I can go back to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Path of least resistance so I can go back to w...</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100wx2</th>\n",
       "      <td>[Ow]</td>\n",
       "      <td>[Hurt my leg and now bedridden. Life is full o...</td>\n",
       "      <td>[Ow, Hurt my leg and now bedridden. Life is fu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Ow Hurt my leg and now bedridden. Life is full...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101tuq</th>\n",
       "      <td>[]</td>\n",
       "      <td>[I had similar problems when I was typing myse...</td>\n",
       "      <td>[I had similar problems when I was typing myse...</td>\n",
       "      <td>5</td>\n",
       "      <td>I had similar problems when I was typing mysel...</td>\n",
       "      <td>2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104bxl</th>\n",
       "      <td>[]</td>\n",
       "      <td>[as a teenager I searched for some romantic an...</td>\n",
       "      <td>[as a teenager I searched for some romantic an...</td>\n",
       "      <td>1</td>\n",
       "      <td>as a teenager I searched for some romantic and...</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        titles                                           contents  \\\n",
       "user_id                                                             \n",
       "100fu2      []  [ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...   \n",
       "100sih      []  [Path of least resistance so I can go back to ...   \n",
       "100wx2    [Ow]  [Hurt my leg and now bedridden. Life is full o...   \n",
       "101tuq      []  [I had similar problems when I was typing myse...   \n",
       "104bxl      []  [as a teenager I searched for some romantic an...   \n",
       "\n",
       "                                               all_content  n_msgs  \\\n",
       "user_id                                                              \n",
       "100fu2   [ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...       1   \n",
       "100sih   [Path of least resistance so I can go back to ...       3   \n",
       "100wx2   [Ow, Hurt my leg and now bedridden. Life is fu...       3   \n",
       "101tuq   [I had similar problems when I was typing myse...       5   \n",
       "104bxl   [as a teenager I searched for some romantic an...       1   \n",
       "\n",
       "                                                      msgs  character_count  \n",
       "user_id                                                                      \n",
       "100fu2   ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...              965  \n",
       "100sih   Path of least resistance so I can go back to w...              485  \n",
       "100wx2   Ow Hurt my leg and now bedridden. Life is full...              103  \n",
       "101tuq   I had similar problems when I was typing mysel...             2091  \n",
       "104bxl   as a teenager I searched for some romantic and...              331  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this case, we want empty titles to not count as one:\n",
    "# replaces field that's entirely space (or empty) with NaN\n",
    "comments_df[\"title\"] = comments_df.title\\\n",
    "    .replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "content_per_user = comments_df\\\n",
    "    .groupby(\"user_id\").agg({\"title\": list, \"content\": list})\\\n",
    "    .rename(columns={\"title\": \"titles\", \"content\": \"contents\"})\n",
    "# ignores any nan title or content\n",
    "for c in [\"titles\", \"contents\"]:\n",
    "    content_per_user[c] = content_per_user[c].apply(lambda l: [e for e in l if not pd.isna(e)])\n",
    "    \n",
    "content_per_user[\"all_content\"] = content_per_user\\\n",
    "    .apply(lambda row: row[\"titles\"] + row[\"contents\"], axis=1)\\\n",
    "\n",
    "# a message is a title or a content, treated equally\n",
    "content_per_user[\"n_msgs\"] = content_per_user.all_content.apply(len)\n",
    "\n",
    "content_per_user[\"msgs\"] = content_per_user.all_content\\\n",
    "    .apply(lambda l: \" \".join(l))\n",
    "\n",
    "content_per_user[\"character_count\"] = content_per_user.msgs.apply(len)\n",
    "content_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "grave-tablet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>contents</th>\n",
       "      <th>all_content</th>\n",
       "      <th>n_msgs</th>\n",
       "      <th>msgs</th>\n",
       "      <th>character_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>mbti_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>[]</td>\n",
       "      <td>[ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...</td>\n",
       "      <td>[ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...</td>\n",
       "      <td>1</td>\n",
       "      <td>ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...</td>\n",
       "      <td>965</td>\n",
       "      <td>100fu2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>[]</td>\n",
       "      <td>[Path of least resistance so I can go back to ...</td>\n",
       "      <td>[Path of least resistance so I can go back to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Path of least resistance so I can go back to w...</td>\n",
       "      <td>485</td>\n",
       "      <td>100sih</td>\n",
       "      <td>ENTP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>[Ow]</td>\n",
       "      <td>[Hurt my leg and now bedridden. Life is full o...</td>\n",
       "      <td>[Ow, Hurt my leg and now bedridden. Life is fu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Ow Hurt my leg and now bedridden. Life is full...</td>\n",
       "      <td>103</td>\n",
       "      <td>100wx2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>[]</td>\n",
       "      <td>[I had similar problems when I was typing myse...</td>\n",
       "      <td>[I had similar problems when I was typing myse...</td>\n",
       "      <td>5</td>\n",
       "      <td>I had similar problems when I was typing mysel...</td>\n",
       "      <td>2091</td>\n",
       "      <td>101tuq</td>\n",
       "      <td>INTJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>[]</td>\n",
       "      <td>[as a teenager I searched for some romantic an...</td>\n",
       "      <td>[as a teenager I searched for some romantic an...</td>\n",
       "      <td>1</td>\n",
       "      <td>as a teenager I searched for some romantic and...</td>\n",
       "      <td>331</td>\n",
       "      <td>104bxl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     titles                                           contents  \\\n",
       "3600     []  [ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...   \n",
       "4118     []  [Path of least resistance so I can go back to ...   \n",
       "3958   [Ow]  [Hurt my leg and now bedridden. Life is full o...   \n",
       "2870     []  [I had similar problems when I was typing myse...   \n",
       "1556     []  [as a teenager I searched for some romantic an...   \n",
       "\n",
       "                                            all_content  n_msgs  \\\n",
       "3600  [ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23...       1   \n",
       "4118  [Path of least resistance so I can go back to ...       3   \n",
       "3958  [Ow, Hurt my leg and now bedridden. Life is fu...       3   \n",
       "2870  [I had similar problems when I was typing myse...       5   \n",
       "1556  [as a teenager I searched for some romantic an...       1   \n",
       "\n",
       "                                                   msgs  character_count  \\\n",
       "3600  ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...              965   \n",
       "4118  Path of least resistance so I can go back to w...              485   \n",
       "3958  Ow Hurt my leg and now bedridden. Life is full...              103   \n",
       "2870  I had similar problems when I was typing mysel...             2091   \n",
       "1556  as a teenager I searched for some romantic and...              331   \n",
       "\n",
       "     user_id mbti_type  \n",
       "3600  100fu2       NaN  \n",
       "4118  100sih      ENTP  \n",
       "3958  100wx2       NaN  \n",
       "2870  101tuq      INTJ  \n",
       "1556  104bxl       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_per_user = content_per_user\\\n",
    "    .merge(users_df[[\"id\", \"mbti_type\"]].rename(columns={\"id\": \"user_id\"}), how=\"left\", left_index=True, right_on=\"user_id\")\n",
    "content_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "removable-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_per_user = content_per_user[[\"user_id\", \"mbti_type\", \"n_msgs\", \"character_count\", \"msgs\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-texas",
   "metadata": {},
   "source": [
    "# 2. Counting and removing items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-guarantee",
   "metadata": {},
   "source": [
    "## What should be cleaned?\n",
    "### Counting and removing\n",
    "* [x] \\n (sometimes not spaced out from the rest) -> count and remove\n",
    "* [x] emojis? 😂 -> Count and remove\n",
    "* [x] emoticons :) -> Count and remove\n",
    "* [x] urls -> count and remove\n",
    "* [x] numbers -> count and remove\n",
    "* markdown tags -> count each and remove\n",
    "\n",
    "### Cleaning\n",
    "* remove special chars as a catch all\n",
    "* tokenize\n",
    "* remove stopwords\n",
    "* lematize\n",
    "\n",
    "For each item, in a specific order:\n",
    "1. count (create a new col)\n",
    "2. remove\n",
    "\n",
    "Seems like a good way to avoid conflicts, such as an emoticon found in a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indonesian-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_per_user[\"msgs_raw\"] = content_per_user.msgs  # keeping a copy of the original msgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-institution",
   "metadata": {},
   "source": [
    "## 2.A. Counting and removing items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satellite-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexes = {\n",
    "    \"url\": r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,4}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\",\n",
    "    \"number_group\": r\"([0-9]+)\",  # also matches on abc1de, do we want that?\n",
    "    \"line_break\": r\"(\\n)\",\n",
    "    \"punctuation\": r\"[.!?\\\\-]\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "improving-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling emojis/emoticons with https://github.com/NeelShah18/emot\n",
    "\n",
    "def count_emojis_and_emoticons(text):\n",
    "    # Note: emoticons count is partial: ^^ is not recognized for example\n",
    "    _sum = 0\n",
    "    for match_obj in [emot.emoji(text), emot.emoticons(text)]:\n",
    "        if type(match_obj) is not list:  # apparently, when there are no matches, output is list\n",
    "            _sum += len(match_obj[\"value\"])\n",
    "    return _sum\n",
    "\n",
    "def remove_emojis(text):\n",
    "    match_obj = emot.emoji(text)\n",
    "    if type(match_obj) is list:\n",
    "        return text\n",
    "    \n",
    "    unique_matches = set(match_obj[\"value\"])\n",
    "    for match in unique_matches:\n",
    "        text = text.replace(match, '')\n",
    "    return text\n",
    "\n",
    "def remove_emoticons(text):\n",
    "    match_obj = emot.emoticons(text)\n",
    "    if type(match_obj) is list:\n",
    "        return text\n",
    "    \n",
    "    unique_matches = set(match_obj[\"value\"])\n",
    "    for match in unique_matches:\n",
    "        text = text.replace(match, '')\n",
    "    return text\n",
    "\n",
    "def handle_emojis_and_emoticons(df, msgs_col_name: str):\n",
    "    df[\"emoji_and_emoticon_count\"] = df[msgs_col_name].apply(count_emojis_and_emoticons)\n",
    "    df[msgs_col_name] = df[msgs_col_name]\\\n",
    "        .apply(remove_emoticons)\\\n",
    "        .apply(remove_emojis)  # maybe we could keep emojis as tokens for vectorization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "contrary-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_and_remove(df, msgs_col_name: str, regex_names: [str]):\n",
    "    \"\"\"\n",
    "    For each regex, counts occurences from the specified col into a new column, and removes them\n",
    "    \"\"\"\n",
    "    for regex_name, regex in regexes.items():\n",
    "        if regex_name in regex_names:\n",
    "            df[f\"{regex_name}_count\"] = df[msgs_col_name]\\\n",
    "                .apply(lambda m: len(re.findall(regex, m)))  # counts\n",
    "            df[msgs_col_name] = df[msgs_col_name].apply(lambda m: re.sub(regex, '', m)) # removes\n",
    "            \n",
    "def add_means_per_msg(df, msgs_count_col: str, char_count_col: str, drop_count_cols: bool):\n",
    "    for count_col in [c for c in df.columns if c.endswith(\"_count\")]:\n",
    "        mean_col_name = \"{item}_msg_mean\".format(item=count_col[:-6])\n",
    "        df[mean_col_name] = df.apply(lambda row: row[count_col] / row[msgs_count_col], axis=1)\n",
    "        if count_col != \"character_count\":  # mean char per char is not super useful \n",
    "            mean_col_name = \"{item}_char_mean\".format(item=count_col[:-6])\n",
    "            df[mean_col_name] = df.apply(lambda row: row[count_col] / row[char_count_col], axis=1)\n",
    "    if drop_count_cols:\n",
    "        df = df[[c for c in df.columns if not c.endswith(\"_count\") or c == \"character_count\"]]\n",
    "    return df\n",
    "            \n",
    "def clean_and_count_all_items(df, msgs_col_name: str):\n",
    "    \"\"\"\n",
    "    For each regex, counts occurences from the specified col into a new column, and removes them\n",
    "    Some are done before remove emojis/emoticons, some after\n",
    "    Can be applied to any df having a column containing msgs as string\n",
    "    \"\"\"\n",
    "    to_do_before_emojis_and_emoticons = [\"url\"]\n",
    "    \n",
    "    count_and_remove(df, msgs_col_name, to_do_before_emojis_and_emoticons)\n",
    "    \n",
    "    handle_emojis_and_emoticons(df, msgs_col_name)\n",
    "    \n",
    "    to_do_after_emojis_and_emoticons = [r for r in list(regexes.keys()) if r not in to_do_before_emojis_and_emoticons]\n",
    "    count_and_remove(df, msgs_col_name, to_do_after_emojis_and_emoticons)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "monetary-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "content_per_user = clean_and_count_all_items(content_per_user, \"msgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "minor-boating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>mbti_type</th>\n",
       "      <th>n_msgs</th>\n",
       "      <th>character_count</th>\n",
       "      <th>msgs</th>\n",
       "      <th>msgs_raw</th>\n",
       "      <th>url_count</th>\n",
       "      <th>emoji_and_emoticon_count</th>\n",
       "      <th>number_group_count</th>\n",
       "      <th>line_break_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>100fu2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>965</td>\n",
       "      <td>ENFJ w (M) here who dated an ENFP w (F)Basical...</td>\n",
       "      <td>ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>100sih</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>3</td>\n",
       "      <td>485</td>\n",
       "      <td>Path of least resistance so I can go back to w...</td>\n",
       "      <td>Path of least resistance so I can go back to w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>100wx2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>Ow Hurt my leg and now bedridden Life is full ...</td>\n",
       "      <td>Ow Hurt my leg and now bedridden. Life is full...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>101tuq</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>5</td>\n",
       "      <td>2091</td>\n",
       "      <td>I had similar problems when I was typing mysel...</td>\n",
       "      <td>I had similar problems when I was typing mysel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>104bxl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>as a teenager I searched for some romantic and...</td>\n",
       "      <td>as a teenager I searched for some romantic and...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id mbti_type  n_msgs  character_count  \\\n",
       "3600  100fu2       NaN       1              965   \n",
       "4118  100sih      ENTP       3              485   \n",
       "3958  100wx2       NaN       3              103   \n",
       "2870  101tuq      INTJ       5             2091   \n",
       "1556  104bxl       NaN       1              331   \n",
       "\n",
       "                                                   msgs  \\\n",
       "3600  ENFJ w (M) here who dated an ENFP w (F)Basical...   \n",
       "4118  Path of least resistance so I can go back to w...   \n",
       "3958  Ow Hurt my leg and now bedridden Life is full ...   \n",
       "2870  I had similar problems when I was typing mysel...   \n",
       "1556  as a teenager I searched for some romantic and...   \n",
       "\n",
       "                                               msgs_raw  url_count  \\\n",
       "3600  ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...          0   \n",
       "4118  Path of least resistance so I can go back to w...          0   \n",
       "3958  Ow Hurt my leg and now bedridden. Life is full...          0   \n",
       "2870  I had similar problems when I was typing mysel...          0   \n",
       "1556  as a teenager I searched for some romantic and...          0   \n",
       "\n",
       "      emoji_and_emoticon_count  number_group_count  line_break_count  \\\n",
       "3600                         1                   9                11   \n",
       "4118                         0                   0                 0   \n",
       "3958                         0                   0                 0   \n",
       "2870                         0                   3                10   \n",
       "1556                         0                   0                 4   \n",
       "\n",
       "      punctuation_count  \n",
       "3600                 11  \n",
       "4118                  7  \n",
       "3958                  5  \n",
       "2870                 28  \n",
       "1556                  3  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_per_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "statutory-holocaust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>mbti_type</th>\n",
       "      <th>n_msgs</th>\n",
       "      <th>character_count</th>\n",
       "      <th>msgs</th>\n",
       "      <th>msgs_raw</th>\n",
       "      <th>character_msg_mean</th>\n",
       "      <th>url_msg_mean</th>\n",
       "      <th>url_char_mean</th>\n",
       "      <th>emoji_and_emoticon_msg_mean</th>\n",
       "      <th>emoji_and_emoticon_char_mean</th>\n",
       "      <th>number_group_msg_mean</th>\n",
       "      <th>number_group_char_mean</th>\n",
       "      <th>line_break_msg_mean</th>\n",
       "      <th>line_break_char_mean</th>\n",
       "      <th>punctuation_msg_mean</th>\n",
       "      <th>punctuation_char_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>100fu2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>965</td>\n",
       "      <td>ENFJ w (M) here who dated an ENFP w (F)Basical...</td>\n",
       "      <td>ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.011399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>100sih</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>3</td>\n",
       "      <td>485</td>\n",
       "      <td>Path of least resistance so I can go back to w...</td>\n",
       "      <td>Path of least resistance so I can go back to w...</td>\n",
       "      <td>161.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.014433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>100wx2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>Ow Hurt my leg and now bedridden Life is full ...</td>\n",
       "      <td>Ow Hurt my leg and now bedridden. Life is full...</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.048544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>101tuq</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>5</td>\n",
       "      <td>2091</td>\n",
       "      <td>I had similar problems when I was typing mysel...</td>\n",
       "      <td>I had similar problems when I was typing mysel...</td>\n",
       "      <td>418.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.013391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>104bxl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>as a teenager I searched for some romantic and...</td>\n",
       "      <td>as a teenager I searched for some romantic and...</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.009063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id mbti_type  n_msgs  character_count  \\\n",
       "3600  100fu2       NaN       1              965   \n",
       "4118  100sih      ENTP       3              485   \n",
       "3958  100wx2       NaN       3              103   \n",
       "2870  101tuq      INTJ       5             2091   \n",
       "1556  104bxl       NaN       1              331   \n",
       "\n",
       "                                                   msgs  \\\n",
       "3600  ENFJ w (M) here who dated an ENFP w (F)Basical...   \n",
       "4118  Path of least resistance so I can go back to w...   \n",
       "3958  Ow Hurt my leg and now bedridden Life is full ...   \n",
       "2870  I had similar problems when I was typing mysel...   \n",
       "1556  as a teenager I searched for some romantic and...   \n",
       "\n",
       "                                               msgs_raw  character_msg_mean  \\\n",
       "3600  ENFJ 4w3 (28M) here who dated an ENFP 7w6 (23F...          965.000000   \n",
       "4118  Path of least resistance so I can go back to w...          161.666667   \n",
       "3958  Ow Hurt my leg and now bedridden. Life is full...           34.333333   \n",
       "2870  I had similar problems when I was typing mysel...          418.200000   \n",
       "1556  as a teenager I searched for some romantic and...          331.000000   \n",
       "\n",
       "      url_msg_mean  url_char_mean  emoji_and_emoticon_msg_mean  \\\n",
       "3600           0.0            0.0                          1.0   \n",
       "4118           0.0            0.0                          0.0   \n",
       "3958           0.0            0.0                          0.0   \n",
       "2870           0.0            0.0                          0.0   \n",
       "1556           0.0            0.0                          0.0   \n",
       "\n",
       "      emoji_and_emoticon_char_mean  number_group_msg_mean  \\\n",
       "3600                      0.001036                    9.0   \n",
       "4118                      0.000000                    0.0   \n",
       "3958                      0.000000                    0.0   \n",
       "2870                      0.000000                    0.6   \n",
       "1556                      0.000000                    0.0   \n",
       "\n",
       "      number_group_char_mean  line_break_msg_mean  line_break_char_mean  \\\n",
       "3600                0.009326                 11.0              0.011399   \n",
       "4118                0.000000                  0.0              0.000000   \n",
       "3958                0.000000                  0.0              0.000000   \n",
       "2870                0.001435                  2.0              0.004782   \n",
       "1556                0.000000                  4.0              0.012085   \n",
       "\n",
       "      punctuation_msg_mean  punctuation_char_mean  \n",
       "3600             11.000000               0.011399  \n",
       "4118              2.333333               0.014433  \n",
       "3958              1.666667               0.048544  \n",
       "2870              5.600000               0.013391  \n",
       "1556              3.000000               0.009063  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_per_user = add_means_per_msg(df=content_per_user, msgs_count_col=\"n_msgs\",\n",
    "                                     char_count_col=\"character_count\", drop_count_cols=True)\n",
    "content_per_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-fishing",
   "metadata": {},
   "source": [
    "## 2.B Cleaning msgs into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "lightweight-statistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENFJ w (M) here who dated an ENFP w (F)Basically, when something goes unexpectedly wrong, it is like the end of the world to me Nothing can go right anymore and it takes time for me to get back on track But what I love most is getting some air from time to time A few months back I was quite exhausted of being with her because I had to focus on my things first and on the other hand she was constantly on demand of new experiences and so on, even though she is/was literally the perfect girl to meAnd actually she ended up dumping me and I was so devastated for the next  monthsSo, IMO the best move you can do to get him back is to trully ignore him and enjoy being with others and friends He will definitely notice you are doing great with others while he still hermitting and overthinkingWe love to be loved but we hate more to be ignored, bear this in mindI can assure you within  weeks you'll be dating again ^^' (probably  ) \n",
      "     |\n",
      "     v\n",
      "['enfj', 'dated', 'enfp', 'basically', 'something', 'go', 'unexpectedly', 'wrong', 'like', 'end', 'world', 'nothing', 'go', 'right', 'anymore', 'take', 'time', 'get', 'back', 'track', 'love', 'getting', 'air', 'time', 'time', 'month', 'back', 'quite', 'exhausted', 'focus', 'thing', 'first', 'hand', 'constantly', 'demand', 'new', 'experience', 'even', 'though', 'literally', 'perfect', 'girl', 'meand', 'actually', 'ended', 'dumping', 'devastated', 'next', 'monthsso', 'imo', 'best', 'move', 'get', 'back', 'trully', 'ignore', 'enjoy', 'others', 'friend', 'definitely', 'notice', 'great', 'others', 'still', 'hermitting', 'overthinkingwe', 'love', 'loved', 'hate', 'ignored', 'bear', 'mindi', 'assure', 'within', 'week', 'dating', 'probably']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W|_', ' ', text) # removes special chars\n",
    "    text = re.sub(r'\\s+', ' ', text) # removes multiple spaces\n",
    "    text = re.sub(r'^\\s|\\s$', '', text) # removes space at the start or end of the string\n",
    "    \n",
    "    tokens = word_tokenize(text)  # tokenizes\n",
    "    \n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")  # are all msgs in english?\n",
    "    tokens = [token for token in tokens if token not in stopwords] # removes stopwords\n",
    "    tokens = [token for token in tokens if len(token) > 1]  # removes 1-char tokens\n",
    "    \n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    tokens = [wn.lemmatize(token) for token in tokens] # lematizes=roots words\n",
    "    return tokens\n",
    "\n",
    "example_msg = content_per_user.iloc[0].msgs\n",
    "print(\"{} \\n     |\\n     v\\n{}\".format(\n",
    "    example_msg,\n",
    "    clean_text(example_msg)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "separate-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.51 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msgs</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>ENFJ w (M) here who dated an ENFP w (F)Basical...</td>\n",
       "      <td>[enfj, dated, enfp, basically, something, go, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>Path of least resistance so I can go back to w...</td>\n",
       "      <td>[path, least, resistance, go, back, whatever, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>Ow Hurt my leg and now bedridden Life is full ...</td>\n",
       "      <td>[ow, hurt, leg, bedridden, life, full, well, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>I had similar problems when I was typing mysel...</td>\n",
       "      <td>[similar, problem, typing, intj, hard, took, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>as a teenager I searched for some romantic and...</td>\n",
       "      <td>[teenager, searched, romantic, hidden, spiritu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   msgs  \\\n",
       "3600  ENFJ w (M) here who dated an ENFP w (F)Basical...   \n",
       "4118  Path of least resistance so I can go back to w...   \n",
       "3958  Ow Hurt my leg and now bedridden Life is full ...   \n",
       "2870  I had similar problems when I was typing mysel...   \n",
       "1556  as a teenager I searched for some romantic and...   \n",
       "\n",
       "                                                 tokens  \n",
       "3600  [enfj, dated, enfp, basically, something, go, ...  \n",
       "4118  [path, least, resistance, go, back, whatever, ...  \n",
       "3958  [ow, hurt, leg, bedridden, life, full, well, p...  \n",
       "2870  [similar, problem, typing, intj, hard, took, y...  \n",
       "1556  [teenager, searched, romantic, hidden, spiritu...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "content_per_user[\"tokens\"] = content_per_user.msgs.apply(clean_text)\n",
    "content_per_user[[\"msgs\", \"tokens\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "restricted-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_per_user_output = content_per_user[[\"user_id\", \"mbti_type\", \"n_msgs\", \"character_count\", \"tokens\"] + [c for c in content_per_user.columns if c.endswith(\"_mean\")]]\\\n",
    "    .reset_index(drop=True)\n",
    "content_per_user_output.to_feather(\"../data/stats_and_tokens_per_user.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suitable-client",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>mbti_type</th>\n",
       "      <th>n_msgs</th>\n",
       "      <th>character_count</th>\n",
       "      <th>tokens</th>\n",
       "      <th>character_msg_mean</th>\n",
       "      <th>url_msg_mean</th>\n",
       "      <th>url_char_mean</th>\n",
       "      <th>emoji_and_emoticon_msg_mean</th>\n",
       "      <th>emoji_and_emoticon_char_mean</th>\n",
       "      <th>number_group_msg_mean</th>\n",
       "      <th>number_group_char_mean</th>\n",
       "      <th>line_break_msg_mean</th>\n",
       "      <th>line_break_char_mean</th>\n",
       "      <th>punctuation_msg_mean</th>\n",
       "      <th>punctuation_char_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100fu2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>965</td>\n",
       "      <td>[enfj, dated, enfp, basically, something, go, ...</td>\n",
       "      <td>965.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.011399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100sih</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>3</td>\n",
       "      <td>485</td>\n",
       "      <td>[path, least, resistance, go, back, whatever, ...</td>\n",
       "      <td>161.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.014433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100wx2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>103</td>\n",
       "      <td>[ow, hurt, leg, bedridden, life, full, well, p...</td>\n",
       "      <td>34.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.048544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101tuq</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>5</td>\n",
       "      <td>2091</td>\n",
       "      <td>[similar, problem, typing, intj, hard, took, y...</td>\n",
       "      <td>418.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.013391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104bxl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>[teenager, searched, romantic, hidden, spiritu...</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.012085</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.009063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id mbti_type  n_msgs  character_count  \\\n",
       "0  100fu2       NaN       1              965   \n",
       "1  100sih      ENTP       3              485   \n",
       "2  100wx2       NaN       3              103   \n",
       "3  101tuq      INTJ       5             2091   \n",
       "4  104bxl       NaN       1              331   \n",
       "\n",
       "                                              tokens  character_msg_mean  \\\n",
       "0  [enfj, dated, enfp, basically, something, go, ...          965.000000   \n",
       "1  [path, least, resistance, go, back, whatever, ...          161.666667   \n",
       "2  [ow, hurt, leg, bedridden, life, full, well, p...           34.333333   \n",
       "3  [similar, problem, typing, intj, hard, took, y...          418.200000   \n",
       "4  [teenager, searched, romantic, hidden, spiritu...          331.000000   \n",
       "\n",
       "   url_msg_mean  url_char_mean  emoji_and_emoticon_msg_mean  \\\n",
       "0           0.0            0.0                          1.0   \n",
       "1           0.0            0.0                          0.0   \n",
       "2           0.0            0.0                          0.0   \n",
       "3           0.0            0.0                          0.0   \n",
       "4           0.0            0.0                          0.0   \n",
       "\n",
       "   emoji_and_emoticon_char_mean  number_group_msg_mean  \\\n",
       "0                      0.001036                    9.0   \n",
       "1                      0.000000                    0.0   \n",
       "2                      0.000000                    0.0   \n",
       "3                      0.000000                    0.6   \n",
       "4                      0.000000                    0.0   \n",
       "\n",
       "   number_group_char_mean  line_break_msg_mean  line_break_char_mean  \\\n",
       "0                0.009326                 11.0              0.011399   \n",
       "1                0.000000                  0.0              0.000000   \n",
       "2                0.000000                  0.0              0.000000   \n",
       "3                0.001435                  2.0              0.004782   \n",
       "4                0.000000                  4.0              0.012085   \n",
       "\n",
       "   punctuation_msg_mean  punctuation_char_mean  \n",
       "0             11.000000               0.011399  \n",
       "1              2.333333               0.014433  \n",
       "2              1.666667               0.048544  \n",
       "3              5.600000               0.013391  \n",
       "4              3.000000               0.009063  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_per_user_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cloudy-veteran",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-e6b0a3b9c2aa>:18: FutureWarning: Index.ravel returning ndarray is deprecated; in a future version this will return a view on self.\n",
      "  df_per_type.columns = [\"_\".join(x) for x in df_per_type.columns.ravel()]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th>msgs</th>\n",
       "      <th>msgs_per_individual</th>\n",
       "      <th>characters</th>\n",
       "      <th>tokens</th>\n",
       "      <th>character_msg_mean</th>\n",
       "      <th>url_msg_mean</th>\n",
       "      <th>url_char_mean</th>\n",
       "      <th>emoji_and_emoticon_msg_mean</th>\n",
       "      <th>emoji_and_emoticon_char_mean</th>\n",
       "      <th>number_group_msg_mean</th>\n",
       "      <th>number_group_char_mean</th>\n",
       "      <th>line_break_msg_mean</th>\n",
       "      <th>line_break_char_mean</th>\n",
       "      <th>punctuation_msg_mean</th>\n",
       "      <th>punctuation_char_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mbti_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENFJ</th>\n",
       "      <td>105</td>\n",
       "      <td>396</td>\n",
       "      <td>3.771429</td>\n",
       "      <td>149528</td>\n",
       "      <td>[yeah, felt, although, understand, ability, ma...</td>\n",
       "      <td>377.943008</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.366218</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>1.802482</td>\n",
       "      <td>0.003463</td>\n",
       "      <td>5.439475</td>\n",
       "      <td>0.020784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENFP</th>\n",
       "      <td>171</td>\n",
       "      <td>621</td>\n",
       "      <td>3.631579</td>\n",
       "      <td>171011</td>\n",
       "      <td>[wan, na, join, gang, hsp, happy, meet, oh, ac...</td>\n",
       "      <td>276.627288</td>\n",
       "      <td>0.017149</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.179677</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.293508</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>1.254692</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>3.857329</td>\n",
       "      <td>0.015681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTJ</th>\n",
       "      <td>142</td>\n",
       "      <td>738</td>\n",
       "      <td>5.197183</td>\n",
       "      <td>166606</td>\n",
       "      <td>[obsession, selfimprovement, spent, teenage, y...</td>\n",
       "      <td>219.381910</td>\n",
       "      <td>0.016341</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.081791</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.276968</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>1.005389</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>3.029230</td>\n",
       "      <td>0.017193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENTP</th>\n",
       "      <td>141</td>\n",
       "      <td>598</td>\n",
       "      <td>4.241135</td>\n",
       "      <td>184050</td>\n",
       "      <td>[path, least, resistance, go, back, whatever, ...</td>\n",
       "      <td>293.342750</td>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.112216</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.333732</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>1.256943</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>4.011158</td>\n",
       "      <td>0.017461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENXP</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7891</td>\n",
       "      <td>[estjs, would, change, could, give, read, seem...</td>\n",
       "      <td>986.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>0.012926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFJ</th>\n",
       "      <td>31</td>\n",
       "      <td>201</td>\n",
       "      <td>6.483871</td>\n",
       "      <td>50569</td>\n",
       "      <td>[vocal, inflection, yes, people, readily, unde...</td>\n",
       "      <td>218.322544</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.025058</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.134095</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.726921</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>3.400043</td>\n",
       "      <td>0.015921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESFP</th>\n",
       "      <td>35</td>\n",
       "      <td>229</td>\n",
       "      <td>6.542857</td>\n",
       "      <td>58497</td>\n",
       "      <td>[yeah, grad, student, doctoral, program, none,...</td>\n",
       "      <td>238.223281</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.179522</td>\n",
       "      <td>0.001589</td>\n",
       "      <td>0.269883</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.687075</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>3.191472</td>\n",
       "      <td>0.019014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTJ</th>\n",
       "      <td>36</td>\n",
       "      <td>194</td>\n",
       "      <td>5.388889</td>\n",
       "      <td>84358</td>\n",
       "      <td>[cognitive, function, opposite, order, make, s...</td>\n",
       "      <td>459.471908</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.273267</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>2.092926</td>\n",
       "      <td>0.003875</td>\n",
       "      <td>5.693913</td>\n",
       "      <td>0.011576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESTP</th>\n",
       "      <td>53</td>\n",
       "      <td>263</td>\n",
       "      <td>4.962264</td>\n",
       "      <td>85611</td>\n",
       "      <td>[oh, yeah, relate, need, develop, like, even, ...</td>\n",
       "      <td>260.665533</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.052550</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>1.142247</td>\n",
       "      <td>0.003264</td>\n",
       "      <td>3.149005</td>\n",
       "      <td>0.013267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFJ</th>\n",
       "      <td>240</td>\n",
       "      <td>967</td>\n",
       "      <td>4.029167</td>\n",
       "      <td>354336</td>\n",
       "      <td>[straight, guy, think, experience, confirm, in...</td>\n",
       "      <td>347.554240</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.093404</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.364133</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>1.561981</td>\n",
       "      <td>0.003303</td>\n",
       "      <td>4.739404</td>\n",
       "      <td>0.015921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFP</th>\n",
       "      <td>112</td>\n",
       "      <td>377</td>\n",
       "      <td>3.366071</td>\n",
       "      <td>114867</td>\n",
       "      <td>[ww, estj, hi, estjs, hope, welli, infp, hope,...</td>\n",
       "      <td>321.975165</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.130049</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.254665</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>1.184727</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>4.331302</td>\n",
       "      <td>0.016619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INFX</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>493</td>\n",
       "      <td>[definitely, notice, chameleon, behavior, work...</td>\n",
       "      <td>98.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.008114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTJ</th>\n",
       "      <td>394</td>\n",
       "      <td>1518</td>\n",
       "      <td>3.852792</td>\n",
       "      <td>453058</td>\n",
       "      <td>[similar, problem, typing, intj, hard, took, y...</td>\n",
       "      <td>291.548351</td>\n",
       "      <td>0.019040</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.039786</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.439604</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>1.291442</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>3.721822</td>\n",
       "      <td>0.015252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTP</th>\n",
       "      <td>208</td>\n",
       "      <td>815</td>\n",
       "      <td>3.918269</td>\n",
       "      <td>221098</td>\n",
       "      <td>[think, si, dominant, function, inf, ne, also,...</td>\n",
       "      <td>254.079067</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.055669</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.265936</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>1.095497</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>3.167894</td>\n",
       "      <td>0.020527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTX</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>112</td>\n",
       "      <td>[want, high, chance, insult, insult, true]</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFJ</th>\n",
       "      <td>98</td>\n",
       "      <td>472</td>\n",
       "      <td>4.816327</td>\n",
       "      <td>224498</td>\n",
       "      <td>[love, embrace, isfj, cute, informative, make,...</td>\n",
       "      <td>330.726715</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.114378</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.360523</td>\n",
       "      <td>0.021550</td>\n",
       "      <td>1.241238</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>4.550133</td>\n",
       "      <td>0.017397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISFP</th>\n",
       "      <td>111</td>\n",
       "      <td>674</td>\n",
       "      <td>6.072072</td>\n",
       "      <td>170265</td>\n",
       "      <td>[everyone, could, benefit, therapy, tbh, isfps...</td>\n",
       "      <td>243.613347</td>\n",
       "      <td>0.059381</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.065616</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.311346</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>1.109692</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>3.274843</td>\n",
       "      <td>0.014347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTJ</th>\n",
       "      <td>115</td>\n",
       "      <td>569</td>\n",
       "      <td>4.947826</td>\n",
       "      <td>156301</td>\n",
       "      <td>[half, full, different, everyone, point, quest...</td>\n",
       "      <td>250.339367</td>\n",
       "      <td>0.028448</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.062637</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.444890</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>1.375840</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>3.434300</td>\n",
       "      <td>0.017192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISTP</th>\n",
       "      <td>174</td>\n",
       "      <td>787</td>\n",
       "      <td>4.522989</td>\n",
       "      <td>201422</td>\n",
       "      <td>[like, reading, aa, well, dont, opportunity, h...</td>\n",
       "      <td>226.062884</td>\n",
       "      <td>0.029145</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.032999</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.251020</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.915017</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>2.895343</td>\n",
       "      <td>0.014863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IXTJ</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>645</td>\n",
       "      <td>[use, si, title, say, ixtj, trouble, telling, ...</td>\n",
       "      <td>161.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.015504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IXTP</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>69</td>\n",
       "      <td>[think, glory, sub, anything, logo]</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XNTP</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1569</td>\n",
       "      <td>[ooo, wan, na, play, forgive, opinion, bit, to...</td>\n",
       "      <td>414.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.013784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>2638</td>\n",
       "      <td>6706</td>\n",
       "      <td>2.542077</td>\n",
       "      <td>1796234</td>\n",
       "      <td>[enfj, dated, enfp, basically, something, go, ...</td>\n",
       "      <td>257.406160</td>\n",
       "      <td>0.034295</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.087915</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.352567</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>1.143257</td>\n",
       "      <td>0.003283</td>\n",
       "      <td>3.419039</td>\n",
       "      <td>0.018767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           individuals  msgs  msgs_per_individual  characters  \\\n",
       "mbti_type                                                       \n",
       "ENFJ               105   396             3.771429      149528   \n",
       "ENFP               171   621             3.631579      171011   \n",
       "ENTJ               142   738             5.197183      166606   \n",
       "ENTP               141   598             4.241135      184050   \n",
       "ENXP                 1     8             8.000000        7891   \n",
       "ESFJ                31   201             6.483871       50569   \n",
       "ESFP                35   229             6.542857       58497   \n",
       "ESTJ                36   194             5.388889       84358   \n",
       "ESTP                53   263             4.962264       85611   \n",
       "INFJ               240   967             4.029167      354336   \n",
       "INFP               112   377             3.366071      114867   \n",
       "INFX                 1     5             5.000000         493   \n",
       "INTJ               394  1518             3.852792      453058   \n",
       "INTP               208   815             3.918269      221098   \n",
       "INTX                 1     2             2.000000         112   \n",
       "ISFJ                98   472             4.816327      224498   \n",
       "ISFP               111   674             6.072072      170265   \n",
       "ISTJ               115   569             4.947826      156301   \n",
       "ISTP               174   787             4.522989      201422   \n",
       "IXTJ                 1     4             4.000000         645   \n",
       "IXTP                 1     1             1.000000          69   \n",
       "XNTP                 2     3             1.500000        1569   \n",
       "NaN               2638  6706             2.542077     1796234   \n",
       "\n",
       "                                                      tokens  \\\n",
       "mbti_type                                                      \n",
       "ENFJ       [yeah, felt, although, understand, ability, ma...   \n",
       "ENFP       [wan, na, join, gang, hsp, happy, meet, oh, ac...   \n",
       "ENTJ       [obsession, selfimprovement, spent, teenage, y...   \n",
       "ENTP       [path, least, resistance, go, back, whatever, ...   \n",
       "ENXP       [estjs, would, change, could, give, read, seem...   \n",
       "ESFJ       [vocal, inflection, yes, people, readily, unde...   \n",
       "ESFP       [yeah, grad, student, doctoral, program, none,...   \n",
       "ESTJ       [cognitive, function, opposite, order, make, s...   \n",
       "ESTP       [oh, yeah, relate, need, develop, like, even, ...   \n",
       "INFJ       [straight, guy, think, experience, confirm, in...   \n",
       "INFP       [ww, estj, hi, estjs, hope, welli, infp, hope,...   \n",
       "INFX       [definitely, notice, chameleon, behavior, work...   \n",
       "INTJ       [similar, problem, typing, intj, hard, took, y...   \n",
       "INTP       [think, si, dominant, function, inf, ne, also,...   \n",
       "INTX              [want, high, chance, insult, insult, true]   \n",
       "ISFJ       [love, embrace, isfj, cute, informative, make,...   \n",
       "ISFP       [everyone, could, benefit, therapy, tbh, isfps...   \n",
       "ISTJ       [half, full, different, everyone, point, quest...   \n",
       "ISTP       [like, reading, aa, well, dont, opportunity, h...   \n",
       "IXTJ       [use, si, title, say, ixtj, trouble, telling, ...   \n",
       "IXTP                     [think, glory, sub, anything, logo]   \n",
       "XNTP       [ooo, wan, na, play, forgive, opinion, bit, to...   \n",
       "NaN        [enfj, dated, enfp, basically, something, go, ...   \n",
       "\n",
       "           character_msg_mean  url_msg_mean  url_char_mean  \\\n",
       "mbti_type                                                    \n",
       "ENFJ               377.943008      0.020785       0.000077   \n",
       "ENFP               276.627288      0.017149       0.000116   \n",
       "ENTJ               219.381910      0.016341       0.000106   \n",
       "ENTP               293.342750      0.014554       0.000090   \n",
       "ENXP               986.375000      0.000000       0.000000   \n",
       "ESFJ               218.322544      0.040323       0.000580   \n",
       "ESFP               238.223281      0.042857       0.000305   \n",
       "ESTJ               459.471908      0.044491       0.000378   \n",
       "ESTP               260.665533      0.020357       0.000132   \n",
       "INFJ               347.554240      0.014549       0.000042   \n",
       "INFP               321.975165      0.018973       0.000067   \n",
       "INFX                98.600000      0.000000       0.000000   \n",
       "INTJ               291.548351      0.019040       0.000097   \n",
       "INTP               254.079067      0.037267       0.000172   \n",
       "INTX                56.000000      0.000000       0.000000   \n",
       "ISFJ               330.726715      0.008277       0.000044   \n",
       "ISFP               243.613347      0.059381       0.000144   \n",
       "ISTJ               250.339367      0.028448       0.000140   \n",
       "ISTP               226.062884      0.029145       0.000094   \n",
       "IXTJ               161.250000      0.000000       0.000000   \n",
       "IXTP                69.000000      0.000000       0.000000   \n",
       "XNTP               414.250000      0.000000       0.000000   \n",
       "NaN                257.406160      0.034295       0.000177   \n",
       "\n",
       "           emoji_and_emoticon_msg_mean  emoji_and_emoticon_char_mean  \\\n",
       "mbti_type                                                              \n",
       "ENFJ                          0.172415                      0.002015   \n",
       "ENFP                          0.179677                      0.004745   \n",
       "ENTJ                          0.081791                      0.000906   \n",
       "ENTP                          0.112216                      0.000996   \n",
       "ENXP                          0.000000                      0.000000   \n",
       "ESFJ                          0.025058                      0.000256   \n",
       "ESFP                          0.179522                      0.001589   \n",
       "ESTJ                          0.027778                      0.000091   \n",
       "ESTP                          0.052550                      0.000602   \n",
       "INFJ                          0.093404                      0.001389   \n",
       "INFP                          0.130049                      0.001355   \n",
       "INFX                          0.000000                      0.000000   \n",
       "INTJ                          0.039786                      0.000516   \n",
       "INTP                          0.055669                      0.000816   \n",
       "INTX                          0.000000                      0.000000   \n",
       "ISFJ                          0.114378                      0.004429   \n",
       "ISFP                          0.065616                      0.000336   \n",
       "ISTJ                          0.062637                      0.000611   \n",
       "ISTP                          0.032999                      0.000261   \n",
       "IXTJ                          0.000000                      0.000000   \n",
       "IXTP                          0.000000                      0.000000   \n",
       "XNTP                          0.000000                      0.000000   \n",
       "NaN                           0.087915                      0.001623   \n",
       "\n",
       "           number_group_msg_mean  number_group_char_mean  line_break_msg_mean  \\\n",
       "mbti_type                                                                       \n",
       "ENFJ                    0.366218                0.003170             1.802482   \n",
       "ENFP                    0.293508                0.003751             1.254692   \n",
       "ENTJ                    0.276968                0.001552             1.005389   \n",
       "ENTP                    0.333732                0.001163             1.256943   \n",
       "ENXP                    0.250000                0.000253             3.000000   \n",
       "ESFJ                    0.134095                0.000864             0.726921   \n",
       "ESFP                    0.269883                0.001855             0.687075   \n",
       "ESTJ                    0.273267                0.000730             2.092926   \n",
       "ESTP                    0.253586                0.001238             1.142247   \n",
       "INFJ                    0.364133                0.002948             1.561981   \n",
       "INFP                    0.254665                0.003983             1.184727   \n",
       "INFX                    0.000000                0.000000             0.000000   \n",
       "INTJ                    0.439604                0.007462             1.291442   \n",
       "INTP                    0.265936                0.001754             1.095497   \n",
       "INTX                    0.000000                0.000000             0.000000   \n",
       "ISFJ                    0.360523                0.021550             1.241238   \n",
       "ISFP                    0.311346                0.007454             1.109692   \n",
       "ISTJ                    0.444890                0.003042             1.375840   \n",
       "ISTP                    0.251020                0.001849             0.915017   \n",
       "IXTJ                    0.000000                0.000000             0.750000   \n",
       "IXTP                    0.000000                0.000000             0.000000   \n",
       "XNTP                    1.750000                0.002363             4.000000   \n",
       "NaN                     0.352567                0.006192             1.143257   \n",
       "\n",
       "           line_break_char_mean  punctuation_msg_mean  punctuation_char_mean  \n",
       "mbti_type                                                                     \n",
       "ENFJ                   0.003463              5.439475               0.020784  \n",
       "ENFP                   0.002837              3.857329               0.015681  \n",
       "ENTJ                   0.003852              3.029230               0.017193  \n",
       "ENTP                   0.003409              4.011158               0.017461  \n",
       "ENXP                   0.003041             12.750000               0.012926  \n",
       "ESFJ                   0.003180              3.400043               0.015921  \n",
       "ESFP                   0.002140              3.191472               0.019014  \n",
       "ESTJ                   0.003875              5.693913               0.011576  \n",
       "ESTP                   0.003264              3.149005               0.013267  \n",
       "INFJ                   0.003303              4.739404               0.015921  \n",
       "INFP                   0.003532              4.331302               0.016619  \n",
       "INFX                   0.000000              0.800000               0.008114  \n",
       "INTJ                   0.004121              3.721822               0.015252  \n",
       "INTP                   0.002822              3.167894               0.020527  \n",
       "INTX                   0.000000              0.000000               0.000000  \n",
       "ISFJ                   0.002602              4.550133               0.017397  \n",
       "ISFP                   0.003485              3.274843               0.014347  \n",
       "ISTJ                   0.004553              3.434300               0.017192  \n",
       "ISTP                   0.002789              2.895343               0.014863  \n",
       "IXTJ                   0.004651              2.500000               0.015504  \n",
       "IXTP                   0.000000              1.000000               0.014493  \n",
       "XNTP                   0.005402              6.500000               0.013784  \n",
       "NaN                    0.003283              3.419039               0.018767  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def aggregate_from_individuals(stats_and_tokens_per_user, by: [str]):\n",
    "    \"\"\"\n",
    "    Groups individuals by the specified column(s)\n",
    "    \"\"\"\n",
    "    df = stats_and_tokens_per_user\n",
    "    aggregation = {\n",
    "        **{\"user_id\": len,\n",
    "           \"n_msgs\": [sum, \"mean\"],\n",
    "           \"character_count\": sum,\n",
    "           \"tokens\": sum},\n",
    "        **{mean_c: np.mean for mean_c in [c for c in df.columns if c.endswith(\"_mean\")]} # add std?\n",
    "    }\n",
    "    \n",
    "    df_per_type = df.groupby(by, dropna=False)\\\n",
    "        .agg(aggregation)\n",
    "    \n",
    "    # flattens the multi_index\n",
    "    df_per_type.columns = [\"_\".join(x) for x in df_per_type.columns.ravel()]\n",
    "    df_per_type.columns = [c.replace('_mean_mean', '_mean').replace('_count_count', '_count') for c in df_per_type.columns]\n",
    "    df_per_type = df_per_type.rename(\n",
    "        columns={\n",
    "            \"tokens_sum\": \"tokens\",\n",
    "            \"character_count_sum\": \"characters\",\n",
    "            \"user_id_len\": \"individuals\",\n",
    "            \"n_msgs_sum\": \"msgs\",\n",
    "            \"n_msgs_mean\": \"msgs_per_individual\"\n",
    "        }\n",
    "    )\n",
    "    return df_per_type\n",
    "\n",
    "df_per_mbti_type = aggregate_from_individuals(content_per_user_output, by=[\"mbti_type\"])\n",
    "df_per_mbti_type.reset_index(drop=True).to_feather(\"../data/stats_and_tokens_per_mbti_type.feather\")\n",
    "df_per_mbti_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-sperm",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
